import pandas as pd
import numpy as np
from sklearn import linear_model, svm
from sklearn.metrics import mean_squared_error, accuracy_score, cohen_kappa_score, classification_report,roc_auc_score, roc_curve,auc
import matplotlib.pyplot as plt
from sklearn.linear_model import Ridge, Lasso, LogisticRegression, Perceptron


#Alpha values
al = [0.01,0.05,0.1,0.5,1,5,10,50,65,100,300,500,1000]
compRidgeMean = []
compRidgeAcc = []
ridgeIntercept = []
ridgeCoef = []
lassoMean = []
lassoAcc = []
lassoIntercept = []
lassoCoef = []


#Reading the csv files
df = pd.read_csv('**\\adult_data_df_final.csv')
df1 = pd.read_csv('**\\adult_test_df.csv')
dftrain = pd.read_csv('**\\adult_data_df_one_hot_encoding.csv')
dftest = pd.read_csv('**\\adult_test_df_one_hot_encoding.csv')

#Creating Dataframes
df.as_matrix()
df1.as_matrix()
dftrain.as_matrix()
dftest.as_matrix()


del dftrain['Income_-1']
del dftrain['Income_1']
del dftest['Income_-1']
del dftest['Income_1']

#Creating Labels
labelstrain  = df['Income']
labelstest = df1['Income']

print("===================Linear Regression=====================")
regr = linear_model.LinearRegression()
regr.fit(dftrain, labelstrain)
pred = regr.predict(dftest)


print("==============Question 1 of the Assignment===================")
print('Coefficients: ', regr.coef_)
print("Mean squared error:",
       mean_squared_error(pred.round(), labelstest)*100)
acc  = cohen_kappa_score(pred.round(), labelstest )
print("Cohen Kappa Score Score:",
     acc*100 )
print("Accuracy Score:", accuracy_score(labelstest,pred.round())*100)

print("=====================Ridge Regression=======================")
for val in al:
  a = pred.reshape(-1,1)
  b = labelstest.reshape(-1,1)
  clf = Ridge(alpha=val)
  clf.fit(b, a)
  ridgePredict = clf.predict(a)
  compRidgeMean.append(mean_squared_error(b, ridgePredict.round())*100) 
  compRidgeAcc.append(accuracy_score(b,ridgePredict.round())*100)
  ridgeIntercept.append(clf.intercept_)
  ridgeCoef.append(clf.coef_)
  
print("===========================Lasso==============================")
for val in al:
   c = pred.reshape(-1,1)
   d = labelstest.reshape(-1,1)
   las = Lasso(alpha=val)
   las.fit(d,c)
   lassoPredict = las.predict(c)
   lassoMean.append((mean_squared_error(d, lassoPredict.round())*100))
   lassoAcc.append(accuracy_score(d, lassoPredict.round())*100)
   lassoIntercept.append(las.intercept_)
   lassoCoef.append(las.coef_)
  

print("========================Logistic Regression=======================") 
logRegr = LogisticRegression()
logRegr.fit(dftrain, labelstrain)
predLog = logRegr.predict(dftest)

score = logRegr.score(dftest,labelstest)
print("Accuracy Score:", score*100)

print(classification_report(labelstest, predLog))
predLog = predLog.astype(np.int)
labelstest = labelstest.astype(np.int)

predLog = np.where(predLog<0, 0,predLog)
print('AUC Score :',roc_auc_score(labelstest , predLog))

#computing ROC area and ROC curve for each class
fpr, tpr, thresholds = roc_curve(labelstest, predLog)
roc_auc = auc(labelstest, predLog,reorder=True)
plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)
# random predictions curve
plt.plot([0, 1], [0, 1], 'k--')  
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.savefig("Logistic Regression Figure")
plt.show()

print("=====================Perceptron=============================")
labelstrainPercep = labelstrain.astype(np.int)
labelstestPercep = labelstest.astype(np.int)
labelstrainPercep = np.where(labelstrain < 0, 0, labelstrain)
labelstestPercep = np.where(labelstest < 0, 0, labelstest)
# Creating a perceptron object with the parameters: 40 iterations (epochs) over the data, and a learning rate of 0.1
percep = Perceptron(n_iter=40 , eta0=0.1, random_state=0)
# Training the perceptron
percep.fit(dftrain, labelstrainPercep)
# Applying the trained perceptron 
predPercep = percep.predict(dftest)
# Viewing the accuracy of the model
accuracyPercep=accuracy_score(labelstestPercep, predPercep)
print('Accuracy:', accuracyPercep*100)
print(classification_report(labelstestPercep, predPercep))

# Computing ROC curve and ROC area for each class
fprPercep, tprPercep, thresholds = roc_curve(labelstestPercep, predPercep)
roc_auc_percep = auc(labelstestPercep, predPercep, reorder=True)
plt.plot(fprPercep, tprPercep, label='ROC curve (area = %0.3f)' % roc_auc_percep)
# random predictions curve
plt.plot([0, 1], [0, 1], 'k--')  
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.savefig("Perceptron Figure")
plt.show()


print("========================SVM==============================")
dftrainSVM = dftrain[:100]
labelstrainSVM = labelstrain[:100]

model = svm.SVC(kernel='linear', C=1E10,cache_size=200,max_iter=-1)
model.fit(dftrainSVM,labelstrainSVM)

predSVM = model.predict(dftest)
accuracySVM = accuracy_score(labelstest,predSVM)
print("Accuracy Score ", accuracySVM * 100)
print(classification_report(labelstest, predSVM))
 
# Computing ROC curve and ROC area for each class
fpr, tpr, thresholds = roc_curve(labelstest, predSVM)
roc_auc = auc(labelstest, predSVM, reorder=True)
plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)
# random predictions curve
plt.plot([0, 1], [0, 1], 'k--')  
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.savefig("SVM Figure")
plt.show()

